{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D, AveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stuartgeman/anaconda/lib/python3.6/site-packages/keras/datasets/reuters.py:47: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(nb_words=500, maxlen=100, test_split=0.2)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=100)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=100)\n",
    "Y_train = np_utils.to_categorical(y_train, 46)\n",
    "Y_test = np_utils.to_categorical(y_test, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5972"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)\n",
    "len(X_test)\n",
    "sum(len(X_train) + len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stuartgeman/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=32, activation=\"relu\", kernel_size=4, padding=\"valid\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/stuartgeman/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=2)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# embedding\n",
    "model.add(Embedding(500, 32, input_length=100))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# convolution layers\n",
    "model.add(Convolution1D(filters=32,\n",
    "                        filter_length=4,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "# dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(46))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stuartgeman/anaconda/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4777 samples, validate on 1195 samples\n",
      "Epoch 1/15\n",
      "4777/4777 [==============================] - 3s 665us/step - loss: 0.0657 - acc: 0.9808 - val_loss: 0.0412 - val_acc: 0.9888\n",
      "Epoch 2/15\n",
      "4777/4777 [==============================] - 3s 634us/step - loss: 0.0369 - acc: 0.9911 - val_loss: 0.0356 - val_acc: 0.9921\n",
      "Epoch 3/15\n",
      "4777/4777 [==============================] - 3s 631us/step - loss: 0.0330 - acc: 0.9921 - val_loss: 0.0354 - val_acc: 0.9916\n",
      "Epoch 4/15\n",
      "4777/4777 [==============================] - 3s 602us/step - loss: 0.0305 - acc: 0.9926 - val_loss: 0.0332 - val_acc: 0.9923\n",
      "Epoch 5/15\n",
      "4777/4777 [==============================] - 3s 618us/step - loss: 0.0281 - acc: 0.9929 - val_loss: 0.0313 - val_acc: 0.9925\n",
      "Epoch 6/15\n",
      "4777/4777 [==============================] - 3s 675us/step - loss: 0.0259 - acc: 0.9932 - val_loss: 0.0303 - val_acc: 0.9927\n",
      "Epoch 7/15\n",
      "4777/4777 [==============================] - 3s 657us/step - loss: 0.0240 - acc: 0.9936 - val_loss: 0.0315 - val_acc: 0.9925\n",
      "Epoch 8/15\n",
      "4777/4777 [==============================] - 4s 758us/step - loss: 0.0224 - acc: 0.9941 - val_loss: 0.0299 - val_acc: 0.9927\n",
      "Epoch 9/15\n",
      "4777/4777 [==============================] - 4s 748us/step - loss: 0.0204 - acc: 0.9944 - val_loss: 0.0303 - val_acc: 0.9928\n",
      "Epoch 10/15\n",
      "4777/4777 [==============================] - 3s 697us/step - loss: 0.0190 - acc: 0.9947 - val_loss: 0.0302 - val_acc: 0.9928\n",
      "Epoch 11/15\n",
      "4777/4777 [==============================] - 3s 693us/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0308 - val_acc: 0.9928\n",
      "Epoch 12/15\n",
      "4777/4777 [==============================] - 3s 690us/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0308 - val_acc: 0.9928\n",
      "Epoch 13/15\n",
      "4777/4777 [==============================] - 3s 686us/step - loss: 0.0149 - acc: 0.9953 - val_loss: 0.0328 - val_acc: 0.9928\n",
      "Epoch 14/15\n",
      "4777/4777 [==============================] - 3s 687us/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0326 - val_acc: 0.9927\n",
      "Epoch 15/15\n",
      "4777/4777 [==============================] - 3s 678us/step - loss: 0.0130 - acc: 0.9957 - val_loss: 0.0339 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1186d4908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=32, nb_epoch=15, verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
